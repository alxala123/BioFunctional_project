nodes <- data.frame(id = paste(ontology, all_groups, sep = "_"), label = ontology, group = all_groups,
first_anc = unique(ontology_data$first_ancestor_name), title = ontology)
# Create a vector of arrow types based on UP_DOWN values
arrow_types_goea <- ifelse(ontology_data$UP_DOWN == "UP", "to",
ifelse(ontology_data$UP_DOWN == "DOWN", "to", "none"))
# Create edges based on filtered data for the current ontology
edges <- data.frame(from = paste(ontology, ontology_data$GROUP_1, sep = "_"),
to = paste(ontology, ontology_data$GROUP_2, sep = "_"),
arrows = arrow_types_goea,
color = ifelse(ontology_data$UP_DOWN == "UP", "blue",
ifelse(ontology_data$UP_DOWN == "DOWN", "red", "black")),
title = paste("EA_value:", ontology_data$EA_VALUE))  # Tooltip to show EA_value
# Append nodes and edges to the lists
all_nodes[[ontology]] <- nodes
all_edges[[ontology]] <- edges
}
# Combine all nodes and edges
all_nodes_combined <- do.call(rbind, all_nodes)
all_edges_combined <- do.call(rbind, all_edges)
# Render the network visualization
output$network_go <- renderVisNetwork({
visNetwork(all_nodes_combined, edges = all_edges_combined, main = "Sample", width = "100%", height = "100%") %>%
visNodes(color = list(border = "black"), shadow = TRUE) %>%  # Setting node border color and adding shadow
visEdges(arrows = "to") %>%
visGroups(groupname = "group", color = list(background = rainbow(length(unique(all_nodes_combined$group))))) %>%
visLegend(main = "Groups", useGroups = TRUE, position = "left", zoom = FALSE) %>%
visOptions(highlightNearest = TRUE, selectedBy = "first_anc")
})
arrow_colors <- c("Up-regulated" = "blue", "Down-regulated" = "red", "Neutral" = "black")
# Renderizado dinámico de la leyenda
output$legend_go <- renderUI({
tagList(
tags$h3("Legend"),
tags$h4("Arrows"),
lapply(names(arrow_colors), function(arrow) {
tags$div(style = "margin-bottom: 10px;",
tags$div(style = paste("display: inline-block; width: 20px; height: 2px; background-color:", arrow_colors[arrow], ";")),
arrow)
})
)
})
output$text_go <-renderText({
"Download a comprehensive prompt designed to assist in the analysis of Gene Ontology (GO) enrichment across your study.
This prompt includes detailed information on the most enriched ontologies, samples analyzed, descriptions of GO terms, and more. It is a valuable
tool for scientists and researchers conducting in-depth biological data analysis."
})
output$download_prompt_go <- downloadHandler(
filename = function() {
paste("prompt-", Sys.Date(), ".txt", sep = "")
},
content = function(file) {
top_ontologies <- filtered_data %>%
arrange(desc(EA_VALUE)) %>%
head(20)
intro_text <- "Write an exhaustive analysis focusing on biological experimental conclusions to learn how the diseases are doing on a Gene Ontology (GO) enrichment dataset for CU or EC, taking the main ideas for all the dataset without specifying in each of them. The dataset includes enrichment information for the 15 most enriched ontologies in the dataset. Each entry in the dataset has the following attributes:
Ontology: The GO identifier.
Sample: Sample used for enrichment analysis.
Description: Description of the GO term.
Disease: Disease studied.
Group_1: First group for comparison.
Group_2: Second group for comparison.
ea_value: Enrichment value.
first_ancestor: The most general ancestor node in the GO hierarchy.
So here are the gene ontologies to analyze:\\n\\n"
ontology_list <- character(nrow(top_ontologies))
for (i in seq_len(nrow(top_ontologies))) {
ontology_info <- paste(
"- Ontology:", top_ontologies$ONTOLOGY[i],
"| Sample:", top_ontologies$sample[i],
"| Description:", top_ontologies$ONT_DESCRIPTION[i],
"| Disease:", top_ontologies$Disease[i],
"| Group_1:", top_ontologies$GROUP_1[i],
"| Group_2:", top_ontologies$GROUP_2[i],
"| ea_value:", top_ontologies$EA_VALUE[i],
"| first_ancestor:", top_ontologies$first_ancestor_name[i],
sep = " "
)
# Append each ontology_info to ontology_list
ontology_list[i] <- ontology_info
}
# Combine all ontology_list elements into a single string separated by newline characters
ontology_list_text <- paste(ontology_list, collapse = "\\n")
# Combine the introductory text and the ontology list text
final_text <- paste(intro_text, ontology_list_text, sep = "")
# Write the final text to the file
writeLines(final_text, file)
})
})
})
output$download_network_go <- downloadHandler(
filename = function() {
paste('network-', Sys.Date(), '.html', sep='')
},
content = function(con)
visNetwork(nodes, edges = filtered_edges, main = "Sample", width = "100%") %>%
visNodes(color = list(background = "white", border = "black"), size = "value") %>%
visGroups(groupname = "group", color = list(border = "black", background = rainbow(length(group_names), start = 0, end = 1)), legend = TRUE) %>%
visPhysics(
enabled = TRUE,
repulsion = list(nodeDistance = 1)
) %>%
visOptions(highlightNearest = TRUE, selectedBy = "first_anc") %>%
visLegend(main = "Group", useGroups = TRUE, zoom = FALSE) %>%
visSave(con)
)
# Lógica para limpiar los datos de análisis funcional de KEGG
observeEvent(input$clear_go_network, {
# Eliminar la tabla y el archivo cargado
output$network_go <- renderDataTable({ NULL })
unlink(input$file_go_network$datapath)  # Eliminar el archivo cargado
})
# Lógica para procesar el archivo y generar el heatmap
observeEvent(input$file_heatmap_go, {
req(input$file_heatmap_go)
dataset <- read.csv(input$file_heatmap_go$datapath, stringsAsFactors = FALSE)
dataset <- analyze_regulation(dataset)
# Actualización de selectInput
updateSelectInput(session, "sample_heatmap_go", choices = unique(dataset$sample))
updateSelectInput(session, "disease_heatmap_go", choices = unique(dataset$Disease))
# Observador para actualizar las ontologías en base a las selecciones de sample y disease
observeEvent(input$sample_heatmap_go, {
req(input$sample_heatmap_go, input$disease_heatmap_go)
# Filtrar datos
filtered_data <- dataset %>%
filter(sample == input$sample_heatmap_go, Disease == input$disease_heatmap_go)
# Actualizar el selectInput de ONT_DESCRIPTION
updateSelectInput(session, "ont_description_heatmap_go", choices = unique(filtered_data$ONT_DESCRIPTION))
})
# Observador para crear el heatmap basado en las selecciones del usuario
observeEvent(input$ont_description_heatmap_go, {
req(input$ont_description_heatmap_go)
# Filtrar datos basados en las selecciones del usuario
filtered_data <- dataset %>%
filter(sample == input$sample_heatmap_go,
Disease == input$disease_heatmap_go,
ONT_DESCRIPTION == input$ont_description_heatmap_go)  # Añadir el filtro de ONT_DESCRIPTION
# Agrupar y resumir los datos
heatmap_data <- filtered_data %>%
group_by(GROUP, ONTOLOGY) %>%
summarize(EA_VALUE = mean(EA_VALUE, na.rm = TRUE), .groups = 'drop')
# Crear el heatmap
output$heatmap_plot_go <- renderPlotly({
p <- ggplot(heatmap_data, aes(x = ONTOLOGY, y = GROUP, fill = EA_VALUE)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
labs(
title = paste("Heatmap de la Muestra:", input$sample_heatmap_go,
"y Enfermedad:", input$disease_heatmap_go),
x = "Ontologías",
y = "Grupo Experimental",
fill = "Valor de EA (EA_VALUE)"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
)
ggplotly(p, tooltip = c("x", "y", "fill"))  # Agrega tooltips para mostrar valores
})
})
# Descargar el heatmap
output$download_heatmap_go <- downloadHandler(
filename = function() {
paste('heatmap_go-', Sys.Date(), '.png', sep = '')
},
content = function(file) {
ggsave(file, plot = last_plot(), device = "png", width = 8, height = 6)
}
)
})
}
# Inicia la aplicación Shiny
shinyApp(ui, server)
# Fuente de scripts si hay otros archivos necesarios
source(here::here("code", "funciones_analisis_datos.R"))
source(here::here("code", "aplicacion_biofunctional.R"))
# Inicia la aplicación Shiny
shinyApp(ui, server)
# Inicia la aplicación Shiny
shinyApp(ui, server)
# Cargar las librerías necesarias
library(shiny)
library(shinydashboard)
library(httr)
library(rentrez)
library(progressr)
library(DT)
GANGO <- function(taxon, gene, group, All_fields = FALSE) {
# Función para limpiar el nombre del taxón o gen
clean_name <- function(name) {
cleaned <- gsub(" ", "_", name)  # Reemplazar espacios por guiones bajos
return(cleaned)
}
# Función para obtener datos de UniProt
get_uniprot_data <- function(taxon, gene) {
# Limpiar los nombres de los parámetros
cleaned_taxon <- clean_name(taxon)
cleaned_gene <- clean_name(gene)
# Construir la URL base para la consulta
base_url <- "https://rest.uniprot.org/uniprotkb/stream?compressed=true"
# Seleccionar los campos a obtener
if (All_fields) {
fields <- "&fields=accession%2Cgo_f%2Cgo_p%2Cgo_c%2Cxref_kegg%2Cother_fields_if_any"
} else {
fields <- "&fields=accession%2Cgo_f%2Cgo_p%2Cgo_c%2Cxref_kegg"
}
# Crear la consulta combinada para taxón y gen
query <- paste0("&query=%28", cleaned_taxon, "%29+AND+%28", cleaned_gene, "%29+AND+%28reviewed%3Atrue%29")
full_url <- paste0(base_url, fields, "&format=tsv", query)
# Mostrar la URL de la solicitud HTTP para depuración
cat("HTTP Request URL:", full_url, "\n")
# Realizar la solicitud HTTP
content <- httr::GET(full_url, write_disk(tf <- tempfile(fileext = ".tsv")))
# Verificar si la solicitud fue exitosa
if (content$status_code != 200) {
cat("Error: HTTP request failed with status", content$status_code, "\n")
return(NULL)
} else {
# Leer y devolver los datos
data <- read.delim(tf, stringsAsFactors = FALSE)
return(data)
}
}
# Inicializar dataframe vacío para combinar los datos
combined_data <- data.frame()
# Iterar sobre cada taxón y gen
for (i in 1:length(taxon)) {
message <- sprintf("Processing taxon %d/%d: %s", i, length(taxon), taxon[i])
cat(message, "\n")
# Obtener datos de UniProt para el taxón y gen actual
data <- get_uniprot_data(taxon[i], gene[i])
# Verificar si se encontraron datos
if (is.null(data) || nrow(data) == 0) {
cat("Warning: No data found for taxon", taxon[i], "and gene", gene[i], "\n")
} else {
# Agregar información de taxón, gen y grupo a los datos
data$TAXON <- taxon[i]
data$GENE <- gene[i]
data$GROUP <- group[i]
# Combinar los datos en el dataframe 'combined_data'
combined_data <- rbind(combined_data, data)
}
}
# Retornar el dataframe combinado
return(combined_data)
}
# Definir la UI (interfaz de usuario)
ui <- dashboardPage(
dashboardHeader(title = "GANGO - UniProt Data Explorer"),
dashboardSidebar(
sidebarMenu(
menuItem("Query Parameters", tabName = "query"),
textInput("taxon", "Enter Taxon", value = "", placeholder = "Enter taxons separated by commas"),
textInput("gene", "Enter Gene", value = "", placeholder = "Enter genes separated by commas"),
textInput("group", "Enter Group", value = "", placeholder = "Enter groups separated by commas"),
fileInput("file1", "Choose CSV File", accept = c("text/csv", "text/comma-separated-values,text/plain", ".csv")),
actionButton("submit", "Submit")
)
),
dashboardBody(
tabItems(
tabItem(tabName = "query",
fluidRow(
box(title = "Query Results", status = "primary", solidHeader = TRUE, width = 12,
DT::dataTableOutput("results"),
br(),  # Añadir un salto de línea
downloadButton("downloadData", "Download Results", class = "btn-primary")
)
)
)
)
)
)
# Definir el servidor
server <- function(input, output, session) {
# Función para leer los taxones, genes y grupos del archivo subido
read_taxon_file <- function(file) {
data <- read.csv(file$datapath, stringsAsFactors = FALSE)
return(data)
}
# Observador para manejar la carga del archivo
observe({
req(input$file1)
data <- read_taxon_file(input$file1)
# Actualizar los campos de entrada de taxones, genes y grupos
updateTextInput(session, "taxon", value = paste(data[[2]], collapse = ","))
updateTextInput(session, "gene", value = paste(data[[3]], collapse = ","))
updateTextInput(session, "group", value = paste(data[[4]], collapse = ","))
})
# Al hacer clic en el botón de enviar, ejecutar la función GANGO y mostrar los resultados
results <- eventReactive(input$submit, {
req(input$taxon, input$gene, input$group)  # Asegúrate de que se introduzca al menos un taxón, gen y grupo
# Convertir el texto de entrada en vectores separados por comas
taxon <- trimws(unlist(strsplit(input$taxon, ",")))
gene <- trimws(unlist(strsplit(input$gene, ",")))
group <- trimws(unlist(strsplit(input$group, ",")))
# Verificar que las longitudes de taxon, gene y group sean iguales
if (length(taxon) != length(gene) || length(taxon) != length(group)) {
showModal(modalDialog(
title = "Input Error",
"The number of taxons, genes, and groups must match.",
easyClose = TRUE,
footer = NULL
))
return(NULL)
}
# Ejecutar la función GANGO con los valores introducidos
GANGO(taxon, gene, group)
}, ignoreNULL = FALSE)  # Configura ignoreNULL a FALSE para evitar que se ejecute repetidamente
# Mostrar los resultados como un DataTable
output$results <- DT::renderDataTable({
req(results())  # Asegúrate de que hay resultados antes de renderizar
datatable(results(), options = list(pageLength = 10))  # Ajustar opciones según necesidades
})
# Función para manejar la descarga del dataset
output$downloadData <- downloadHandler(
filename = function() {
paste("GANGO_results_", Sys.Date(), ".csv", sep = "")
},
content = function(file) {
write.csv(results(), file, row.names = FALSE)
}
)
}
# Iniciar la aplicación Shiny
shinyApp(ui, server)
library(shiny); runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
View(ancestors_gene_ontologies)
View(ancestors_gene_ontologies)
View(ancestors_gene_ontologies)
runApp('BioFunctional_AA.R')
runApp('code/aplicacion_biofunctional.R')
ancestors_gene_ontologies <- function(ontologies, groups) {
# Función para obtener ancestros de QuickGO
get_ancestors <- function(ontology) {
url <- sprintf("https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/%s/ancestors?relations=is_a%%2Cpart_of%%2Coccurs_in%%2Cregulates",
URLencode(ontology, reserved = TRUE))
response <- tryCatch({
content(GET(url, accept("application/json")), "parsed")
}, error = function(e) {
print(paste("Error al obtener datos para:", ontology))
return(NULL)
})
# Depuración: Verificar respuesta de la API
print(paste("Consultando:", ontology))
print(response)
# Validar respuesta y extraer ancestros
if (!is.null(response$results) && length(response$results) > 0) {
if (!response$results[[1]]$isObsolete) {
ancestors <- response$results[[1]]$ancestors
return(setdiff(ancestors, ontology))  # Excluir el propio término
}
}
return(NA)  # Si no hay ancestros, devolver NA
}
# Obtener ancestros en paralelo
plan(multisession)  # Usa varios núcleos (ajustar si hay problemas en Windows)
ancestors <- future_lapply(ontologies, get_ancestors)
# Convertir a caracteres y evitar valores NULL
ancestors <- sapply(ancestors, function(x) ifelse(is.null(x), NA, toString(x)))
# Crear dataframe asegurando que cada ontología mantenga su grupo
data <- data.frame(GROUP = groups, ONTOLOGY = ontologies, ANCESTORS = ancestors, stringsAsFactors = FALSE)
# Filtrar filas sin ancestros
data <- data[!is.na(data$ANCESTORS) & data$ANCESTORS != "", ]
return(data)
}
# Lista de paquetes requeridos
required_packages <- c(
"shiny",              # For creating interactive applications
"shinydashboard",     # For creating dashboards within the Shiny application
"shinycssloaders",    # For adding loading indicators
"httr",               # For making HTTP requests
"readr",              # For reading rectangular data (CSV, TSV, etc.)
"dplyr",              # For data manipulation using a consistent set of verbs
"tibble",             # For working with data frames in a modern and consistent way
"future.apply",       # For running functions in parallel to speed up processing
"DT",                 # For displaying interactive tables in Shiny apps
"rvest",              # For web scraping and parsing HTML pages
"visNetwork",         # For creating interactive network visualizations
"bslib",              # For customizing and theming Shiny applications using Bootstrap
"fastmap",            # For creating efficient key-value stores, useful for caching
"shinyBS",            # For adding additional Bootstrap components like modals and tooltips
"shinyjs",            # For using JavaScript in Shiny apps to enhance interactivity
"plotly",
"progressr",
"rentrez",
"tidyr",
"stringr",
"jsonlite"
)
# Instalar y cargar los paquetes
installed_packages <- rownames(installed.packages())
for (pkg in required_packages) {
if (!(pkg %in% installed_packages)) {
install.packages(pkg)
}
library(pkg, character.only = TRUE)
}
test_ontologies <- c("GO:0008150", "GO:0003674")
test_groups <- c("Group1", "Group2")
result <- ancestors_gene_ontologies(test_ontologies, test_groups)
print(result)
get_ancestors <- function(ontology) {
url <- sprintf("https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/%s/ancestors?relations=is_a%%2Cpart_of%%2Coccurs_in%%2Cregulates",
URLencode(ontology, reserved = TRUE))
response <- tryCatch({
content(GET(url, accept("application/json")), "parsed")
}, error = function(e) {
print(paste("Error al obtener datos para:", ontology))
return(NULL)
})
# Depuración: Verificar respuesta de la API
print(paste("Consultando:", ontology))
print(response)
# Validar respuesta y extraer ancestros
if (!is.null(response$results) && length(response$results) > 0) {
if (!response$results[[1]]$isObsolete) {
ancestors <- response$results[[1]]$ancestors
# Check if ancestors only contains the term itself
if (length(ancestors) == 1 && ancestors[[1]] == ontology) {
return(NA)  # Return NA if there are no true ancestors
} else {
return(ancestors)  # Return ancestors as they are
}
}
}
return(NA)  # If no ancestors found
}
result <- ancestors_gene_ontologies(c("GO:0008150"), c("Group1"))
ancestors_gene_ontologies <- function(ontologies, groups) {
# Función para obtener ancestros de QuickGO
get_ancestors <- function(ontology) {
url <- sprintf("https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/%s/ancestors?relations=is_a%%2Cpart_of%%2Coccurs_in%%2Cregulates",
URLencode(ontology, reserved = TRUE))
response <- tryCatch({
content(GET(url, accept("application/json")), "parsed")
}, error = function(e) {
print(paste("Error al obtener datos para:", ontology))
return(NULL)
})
# Depuración: Verificar respuesta de la API
print(paste("Consultando:", ontology))
print(response)
# Validar respuesta y extraer ancestros
if (!is.null(response$results) && length(response$results) > 0) {
if (!response$results[[1]]$isObsolete) {
ancestors <- response$results[[1]]$ancestors
# Check if ancestors only contains the term itself
if (length(ancestors) == 1 && ancestors[[1]] == ontology) {
return(NA)  # Return NA if there are no true ancestors
} else {
return(ancestors)  # Return ancestors as they are
}
}
}
return(NA)  # If no ancestors found
}
# Obtener ancestros en paralelo
plan(multisession)  # Usa varios núcleos (ajustar si hay problemas en Windows)
ancestors <- future_lapply(ontologies, get_ancestors)
# Convertir a caracteres y evitar valores NULL
ancestors <- sapply(ancestors, function(x) ifelse(is.null(x), NA, toString(x)))
# Crear dataframe asegurando que cada ontología mantenga su grupo
data <- data.frame(GROUP = groups, ONTOLOGY = ontologies, ANCESTORS = ancestors, stringsAsFactors = FALSE)
# Filtrar filas sin ancestros
data <- data[!is.na(data$ANCESTORS) & data$ANCESTORS != "", ]
return(data)
}
test_ontologies <- c("GO:0008150", "GO:0003674")
test_groups <- c("Group1", "Group2")
result <- ancestors_gene_ontologies(test_ontologies, test_groups)
print(result)
test_ontologies <- c("GO:0005524", "GO:0003674")
test_groups <- c("Group1", "Group2")
result <- ancestors_gene_ontologies(test_ontologies, test_groups)
print(result)
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
install.packages("here")
library(rlang)
runApp('code/aplicacion_biofunctional.R')
runApp('code/aplicacion_biofunctional.R')
runApp('BioFunctional_AA.R')
install.packages("here")
library(shiny); runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
runApp('BioFunctional_AA.R')
library(dplyr)
getwd()
# Leer el archivo CSV
df <- read.csv("/Users/alex/Downloads/GANGO_BACTERIA_HEALTHY.csv")
View(df)
# Cambiar el orden de las columnas
df <- df %>%
select(taxon, gene, group)
# Ver el dataframe resultante
print(df)
write.csv(df, "GANGO_BACTERIA_HEALTHY_2.csv")
write.csv(df, "/Users/alex/Downloads/GANGO_BACTERIA_HEALTHY_2.csv")
runApp('BioFunctional_AA.R')
runApp('~/Downloads/BioFunctional_2.21/code/aplicacion_biofunctional.R')
runApp('~/Downloads/BioFunctional_2.21/code/aplicacion_biofunctional.R')
runApp('~/Downloads/BioFunctional_2.21/BioFunctional_AA.R')
install.packages("here")
library(shiny); runApp('~/Downloads/BioFunctional_2.21/BioFunctional_AA.R')
